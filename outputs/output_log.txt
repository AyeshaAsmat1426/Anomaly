 * Serving Flask app 'full_final_anomaly detection.py'
 * Debug mode: off
executing train_model()
Input video path: uploads\train_upload\Real.mp4
executing load_and_preprocess_video()
Video path: uploads\train_upload\Real.mp4
Filename: C:\Users\SaadSuleman\OneDrive - Techionik\Documents\Desktop\anomaly_latest\anomaly_detection.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    20    353.8 MiB    353.8 MiB           1   @profile
    21                                         def load_and_preprocess_video(video_path, h, w, return_original=False):
    22    353.8 MiB      0.0 MiB           1       print("executing load_and_preprocess_video()")
    23    353.8 MiB      0.0 MiB           1       start_time = datetime.now()
    24                                         
    25    353.8 MiB      0.0 MiB           1       print("Video path:", video_path)  # Add this line for debugging
    26                                         
    27    358.8 MiB      5.0 MiB           1       cap = cv2.VideoCapture(video_path)
    28                                         
    29                                             # Check if video opened successfully
    30    358.8 MiB      0.0 MiB           1       if not cap.isOpened():
    31                                                 print("Error opening video file:", video_path)  # Add this line for debugging
    32                                                 return None, 0, 0  # Return None along with other values if video cannot be opened
    33                                         
    34    358.8 MiB      0.0 MiB           1       frames = []
    35    358.8 MiB      0.0 MiB           1       original_frames = []
    36                                         
    37    358.8 MiB      0.0 MiB           1       try:
    38                                                 # Get total number of frames in the video
    39    358.8 MiB      0.0 MiB           1           total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    40                                         
    41                                                 # Get frames per second (FPS) of the video
    42    358.8 MiB      0.0 MiB           1           fps = cap.get(cv2.CAP_PROP_FPS)
    43                                         
    44                                                 # Calculate video duration in seconds
    45    358.8 MiB      0.0 MiB           1           video_duration = total_frames / fps
    46                                         
    47    482.8 MiB      0.0 MiB        1493           while True:
    48    485.5 MiB   3963.9 MiB        1493               ret, frame = cap.read()
    49    485.5 MiB     -3.3 MiB        1493               if not ret:
    50    482.9 MiB     -2.6 MiB           1                   break
    51    485.5 MiB     -0.7 MiB        1492               if return_original:
    52                                                         original_frames.append(frame)
    53                                         
    54                                                     # (128,128,1 or 3)
    55    482.8 MiB  -3877.1 MiB        1492               frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    56    482.8 MiB      0.5 MiB        1492               frame = cv2.resize(frame, (h, w))
    57                                                     # Normalizing (why?)
    58    482.8 MiB     36.1 MiB        1492               frame = frame.astype("float32") / 255.0
    59    482.8 MiB      0.0 MiB        1492               frames.append(frame)
    60                                         
    61    456.0 MiB    -26.9 MiB           1           cap.release()
    62    549.2 MiB     93.3 MiB           1           video = np.array(frames)
    63    549.2 MiB      0.0 MiB           1           video = np.expand_dims(video, axis=-1)
    64                                         
    65    549.2 MiB      0.0 MiB           1           end_time = datetime.now()
    66    549.2 MiB      0.0 MiB           1           load_and_preprocess_video_duration = (end_time - start_time).seconds
    67                                         
    68    549.2 MiB      0.0 MiB           1           if return_original:
    69                                                     return video, video_duration, original_frames, load_and_preprocess_video_duration
    70                                                 else:
    71    549.2 MiB      0.0 MiB           1               return video, video_duration, load_and_preprocess_video_duration
    72                                         
    73                                             except Exception as e:
    74                                                 print("Error processing video:", e)
    75                                                 return None, 0, 0
    76                                             if return_original:
    77                                                 return video, video_duration, original_frames, load_and_preprocess_video_duration
    78                                             else:
    79                                                 return video, video_duration, load_and_preprocess_video_duration


Training video frames:  1492
executing build_autoencoder()
Encoding...
Decoding...
Building the autoencoder model...
Filename: C:\Users\SaadSuleman\OneDrive - Techionik\Documents\Desktop\anomaly_latest\anomaly_detection.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    82    454.9 MiB    454.9 MiB           1   @profile
    83                                         def build_autoencoder():
    84    454.9 MiB      0.0 MiB           1           print("executing build_autoencoder()")
    85                                                 # glogally 
    86    454.9 MiB      0.0 MiB           1           h, w = 128, 128
    87    454.9 MiB      0.1 MiB           1           input_img = Input(shape=(h, w, 1)) # channel 1 (gray scale) or 3 (coloured images)
    88                                         
    89                                                 # Encoding
    90    454.9 MiB      0.0 MiB           1           print("Encoding...")
    91    463.4 MiB      8.5 MiB           1           x = Conv2D(16, (3, 3), activation="relu", padding="same")(input_img)
    92    463.4 MiB      0.0 MiB           1           x = MaxPooling2D((2, 2), padding="same")(x)
    93    463.4 MiB      0.0 MiB           1           x = Conv2D(8, (3, 3), activation="relu", padding="same")(x)
    94    463.4 MiB      0.0 MiB           1           x = Conv2D(8, (3, 3), activation="relu", padding="same")(x)
    95    463.4 MiB      0.0 MiB           1           encoded = MaxPooling2D((2, 2), padding="same")(x)
    96                                         
    97                                                 # Decoding
    98    463.4 MiB      0.0 MiB           1           print("Decoding...")
    99    463.6 MiB      0.1 MiB           1           x = Conv2D(8, (3, 3), activation="relu", padding="same")(encoded)
   100    463.6 MiB      0.0 MiB           1           x = UpSampling2D((2, 2))(x)
   101    463.6 MiB      0.0 MiB           1           x = Conv2D(16, (3, 3), activation="relu", padding="same")(x)
   102    463.6 MiB      0.1 MiB           1           x = Conv2D(16, (3, 3), activation="relu", padding="same")(x)
   103    463.7 MiB      0.0 MiB           1           x = UpSampling2D((2, 2))(x)
   104    463.9 MiB      0.2 MiB           1           decoded = Conv2D(1, (3, 3), activation="sigmoid", padding="same")(x)
   105                                         
   106                                                 # Build the autoencoder model
   107    463.9 MiB      0.0 MiB           1           print("Building the autoencoder model...")
   108    463.9 MiB      0.1 MiB           1           autoencoder = Model(input_img, decoded)
   109    464.0 MiB      0.1 MiB           1           autoencoder.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.MeanSquaredError())
   110                                         
   111    464.0 MiB      0.0 MiB           1           optimizer = tf.keras.optimizers.Adam()
   112                                         
   113    464.0 MiB      0.0 MiB           1           return autoencoder, optimizer


Epoch:  1
executing train_step()
executing train_step()
  Batch 1/298, Loss: 0.084555
  Batch 2/298, Loss: 0.082717
  Batch 3/298, Loss: 0.078079
  Batch 4/298, Loss: 0.075748
  Batch 5/298, Loss: 0.072663
  Batch 6/298, Loss: 0.068808
  Batch 7/298, Loss: 0.064196
  Batch 8/298, Loss: 0.061174
  Batch 9/298, Loss: 0.057671
  Batch 10/298, Loss: 0.054398
  Batch 11/298, Loss: 0.050381
  Batch 12/298, Loss: 0.047858
  Batch 13/298, Loss: 0.045451
  Batch 14/298, Loss: 0.043578
  Batch 15/298, Loss: 0.041425
  Batch 16/298, Loss: 0.038733
  Batch 17/298, Loss: 0.036060
  Batch 18/298, Loss: 0.033116
  Batch 19/298, Loss: 0.029503
  Batch 20/298, Loss: 0.026146
  Batch 21/298, Loss: 0.022324
  Batch 22/298, Loss: 0.018359
  Batch 23/298, Loss: 0.015442
  Batch 24/298, Loss: 0.013563
  Batch 25/298, Loss: 0.013187
  Batch 26/298, Loss: 0.014793
  Batch 27/298, Loss: 0.017067
  Batch 28/298, Loss: 0.014459
  Batch 29/298, Loss: 0.016057
  Batch 30/298, Loss: 0.013649
  Batch 31/298, Loss: 0.013878
  Batch 32/298, Loss: 0.012316
  Batch 33/298, Loss: 0.010656
  Batch 34/298, Loss: 0.011171
  Batch 35/298, Loss: 0.010766
  Batch 36/298, Loss: 0.011238
  Batch 37/298, Loss: 0.011096
  Batch 38/298, Loss: 0.010232
  Batch 39/298, Loss: 0.010237
  Batch 40/298, Loss: 0.010167
  Batch 41/298, Loss: 0.009599
  Batch 42/298, Loss: 0.009716
  Batch 43/298, Loss: 0.010102
  Batch 44/298, Loss: 0.010086
  Batch 45/298, Loss: 0.009983
  Batch 46/298, Loss: 0.012874
  Batch 47/298, Loss: 0.014993
  Batch 48/298, Loss: 0.014358
  Batch 49/298, Loss: 0.014309
  Batch 50/298, Loss: 0.014534
  Batch 51/298, Loss: 0.014457
  Batch 52/298, Loss: 0.013824
  Batch 53/298, Loss: 0.013607
  Batch 54/298, Loss: 0.014026
  Batch 55/298, Loss: 0.014318
  Batch 56/298, Loss: 0.013938
  Batch 57/298, Loss: 0.009165
  Batch 58/298, Loss: 0.008460
  Batch 59/298, Loss: 0.009571
  Batch 60/298, Loss: 0.008732
  Batch 61/298, Loss: 0.009097
  Batch 62/298, Loss: 0.009504
  Batch 63/298, Loss: 0.008550
  Batch 64/298, Loss: 0.008476
  Batch 65/298, Loss: 0.009771
  Batch 66/298, Loss: 0.013115
  Batch 67/298, Loss: 0.012764
  Batch 68/298, Loss: 0.013046
  Batch 69/298, Loss: 0.013374
  Batch 70/298, Loss: 0.013231
  Batch 71/298, Loss: 0.012940
  Batch 72/298, Loss: 0.012515
  Batch 73/298, Loss: 0.012604
  Batch 74/298, Loss: 0.012716
  Batch 75/298, Loss: 0.012532
  Batch 76/298, Loss: 0.012247
  Batch 77/298, Loss: 0.012036
  Batch 78/298, Loss: 0.012052
  Batch 79/298, Loss: 0.012091
  Batch 80/298, Loss: 0.011866
  Batch 81/298, Loss: 0.011782
  Batch 82/298, Loss: 0.011694
  Batch 83/298, Loss: 0.011566
  Batch 84/298, Loss: 0.011446
  Batch 85/298, Loss: 0.011303
  Batch 86/298, Loss: 0.011188
  Batch 87/298, Loss: 0.011047
  Batch 88/298, Loss: 0.010811
  Batch 89/298, Loss: 0.010691
  Batch 90/298, Loss: 0.010567
  Batch 91/298, Loss: 0.010722
  Batch 92/298, Loss: 0.010861
  Batch 93/298, Loss: 0.010773
  Batch 94/298, Loss: 0.010754
  Batch 95/298, Loss: 0.010761
  Batch 96/298, Loss: 0.010652
  Batch 97/298, Loss: 0.010455
  Batch 98/298, Loss: 0.007831
  Batch 99/298, Loss: 0.008206
  Batch 100/298, Loss: 0.008261
  Batch 101/298, Loss: 0.007927
  Batch 102/298, Loss: 0.007854
  Batch 103/298, Loss: 0.008200
  Batch 104/298, Loss: 0.008448
  Batch 105/298, Loss: 0.008663
  Batch 106/298, Loss: 0.007395
  Batch 107/298, Loss: 0.008135
  Batch 108/298, Loss: 0.008118
  Batch 109/298, Loss: 0.008162
  Batch 110/298, Loss: 0.008181
  Batch 111/298, Loss: 0.008100
  Batch 112/298, Loss: 0.007982
  Batch 113/298, Loss: 0.007875
  Batch 114/298, Loss: 0.007783
  Batch 115/298, Loss: 0.007721
  Batch 116/298, Loss: 0.007678
  Batch 117/298, Loss: 0.007629
  Batch 118/298, Loss: 0.007548
  Batch 119/298, Loss: 0.007515
  Batch 120/298, Loss: 0.007432
  Batch 121/298, Loss: 0.007387
  Batch 122/298, Loss: 0.007321
  Batch 123/298, Loss: 0.007260
  Batch 124/298, Loss: 0.007220
  Batch 125/298, Loss: 0.007199
  Batch 126/298, Loss: 0.007178
  Batch 127/298, Loss: 0.007093
  Batch 128/298, Loss: 0.007033
  Batch 129/298, Loss: 0.007001
  Batch 130/298, Loss: 0.006974
  Batch 131/298, Loss: 0.006920
  Batch 132/298, Loss: 0.006901
  Batch 133/298, Loss: 0.006919
  Batch 134/298, Loss: 0.006954
  Batch 135/298, Loss: 0.006966
  Batch 136/298, Loss: 0.006987
  Batch 137/298, Loss: 0.006996
  Batch 138/298, Loss: 0.006988
  Batch 139/298, Loss: 0.006985
  Batch 140/298, Loss: 0.006959
  Batch 141/298, Loss: 0.006949
  Batch 142/298, Loss: 0.007003
  Batch 143/298, Loss: 0.006922
  Batch 144/298, Loss: 0.006895
  Batch 145/298, Loss: 0.006898
  Batch 146/298, Loss: 0.006898
  Batch 147/298, Loss: 0.007159
  Batch 148/298, Loss: 0.008653
  Batch 149/298, Loss: 0.008139
  Batch 150/298, Loss: 0.008195
  Batch 151/298, Loss: 0.008258
  Batch 152/298, Loss: 0.008039
  Batch 153/298, Loss: 0.008109
  Batch 154/298, Loss: 0.007685
  Batch 155/298, Loss: 0.007713
  Batch 156/298, Loss: 0.007680
  Batch 157/298, Loss: 0.007524
  Batch 158/298, Loss: 0.007529
  Batch 159/298, Loss: 0.007410
  Batch 160/298, Loss: 0.007357
  Batch 161/298, Loss: 0.007103
  Batch 162/298, Loss: 0.007137
  Batch 163/298, Loss: 0.009428
  Batch 164/298, Loss: 0.009288
  Batch 165/298, Loss: 0.009194
  Batch 166/298, Loss: 0.009098
  Batch 167/298, Loss: 0.009024
  Batch 168/298, Loss: 0.008949
  Batch 169/298, Loss: 0.008865
  Batch 170/298, Loss: 0.002968
  Batch 171/298, Loss: 0.001440
  Batch 172/298, Loss: 0.001398
  Batch 173/298, Loss: 0.001324
  Batch 174/298, Loss: 0.001351
  Batch 175/298, Loss: 0.001537
  Batch 176/298, Loss: 0.001958
  Batch 177/298, Loss: 0.002480
  Batch 178/298, Loss: 0.002347
  Batch 179/298, Loss: 0.002509
  Batch 180/298, Loss: 0.002654
  Batch 181/298, Loss: 0.002684
  Batch 182/298, Loss: 0.002474
  Batch 183/298, Loss: 0.002459
  Batch 184/298, Loss: 0.002270
  Batch 185/298, Loss: 0.002023
  Batch 186/298, Loss: 0.002257
  Batch 187/298, Loss: 0.002199
  Batch 188/298, Loss: 0.002392
  Batch 189/298, Loss: 0.005136
  Batch 190/298, Loss: 0.006797
  Batch 191/298, Loss: 0.007017
  Batch 192/298, Loss: 0.007087
  Batch 193/298, Loss: 0.007389
  Batch 194/298, Loss: 0.007129
  Batch 195/298, Loss: 0.006847
  Batch 196/298, Loss: 0.006758
  Batch 197/298, Loss: 0.006854
  Batch 198/298, Loss: 0.006678
  Batch 199/298, Loss: 0.006674
  Batch 200/298, Loss: 0.006822
  Batch 201/298, Loss: 0.006785
  Batch 202/298, Loss: 0.006772
  Batch 203/298, Loss: 0.006747
  Batch 204/298, Loss: 0.006779
  Batch 205/298, Loss: 0.006943
  Batch 206/298, Loss: 0.007123
  Batch 207/298, Loss: 0.007251
  Batch 208/298, Loss: 0.007127
  Batch 209/298, Loss: 0.007162
  Batch 210/298, Loss: 0.006863
  Batch 211/298, Loss: 0.006674
  Batch 212/298, Loss: 0.006921
  Batch 213/298, Loss: 0.007017
  Batch 214/298, Loss: 0.007114
  Batch 215/298, Loss: 0.007384
  Batch 216/298, Loss: 0.008015
  Batch 217/298, Loss: 0.007880
  Batch 218/298, Loss: 0.008423
  Batch 219/298, Loss: 0.008414
  Batch 220/298, Loss: 0.008493
  Batch 221/298, Loss: 0.008508
  Batch 222/298, Loss: 0.008483
  Batch 223/298, Loss: 0.008563
  Batch 224/298, Loss: 0.008429
  Batch 225/298, Loss: 0.008390
  Batch 226/298, Loss: 0.008278
  Batch 227/298, Loss: 0.008237
  Batch 228/298, Loss: 0.006939
  Batch 229/298, Loss: 0.007124
  Batch 230/298, Loss: 0.006942
  Batch 231/298, Loss: 0.006905
  Batch 232/298, Loss: 0.006724
  Batch 233/298, Loss: 0.006519
  Batch 234/298, Loss: 0.006507
  Batch 235/298, Loss: 0.006573
  Batch 236/298, Loss: 0.006609
  Batch 237/298, Loss: 0.006671
  Batch 238/298, Loss: 0.006658
  Batch 239/298, Loss: 0.006517
  Batch 240/298, Loss: 0.006242
  Batch 241/298, Loss: 0.005973
  Batch 242/298, Loss: 0.006023
  Batch 243/298, Loss: 0.006181
  Batch 244/298, Loss: 0.006241
  Batch 245/298, Loss: 0.006350
  Batch 246/298, Loss: 0.006634
  Batch 247/298, Loss: 0.006813
  Batch 248/298, Loss: 0.006765
  Batch 249/298, Loss: 0.006786
  Batch 250/298, Loss: 0.006701
  Batch 251/298, Loss: 0.006481
  Batch 252/298, Loss: 0.006182
  Batch 253/298, Loss: 0.006051
  Batch 254/298, Loss: 0.006121
  Batch 255/298, Loss: 0.006217
  Batch 256/298, Loss: 0.006881
  Batch 257/298, Loss: 0.009306
  Batch 258/298, Loss: 0.009402
  Batch 259/298, Loss: 0.009452
  Batch 260/298, Loss: 0.009460
  Batch 261/298, Loss: 0.009379
  Batch 262/298, Loss: 0.009015
  Batch 263/298, Loss: 0.009078
  Batch 264/298, Loss: 0.009394
  Batch 265/298, Loss: 0.008720
  Batch 266/298, Loss: 0.008539
  Batch 267/298, Loss: 0.008050
  Batch 268/298, Loss: 0.007721
  Batch 269/298, Loss: 0.008384
  Batch 270/298, Loss: 0.008304
  Batch 271/298, Loss: 0.008379
  Batch 272/298, Loss: 0.009046
  Batch 273/298, Loss: 0.009575
  Batch 274/298, Loss: 0.010151
  Batch 275/298, Loss: 0.009713
  Batch 276/298, Loss: 0.009585
  Batch 277/298, Loss: 0.009651
  Batch 278/298, Loss: 0.010153
  Batch 279/298, Loss: 0.009878
  Batch 280/298, Loss: 0.009860
  Batch 281/298, Loss: 0.009810
  Batch 282/298, Loss: 0.009490
  Batch 283/298, Loss: 0.009492
  Batch 284/298, Loss: 0.009604
  Batch 285/298, Loss: 0.009890
  Batch 286/298, Loss: 0.009716
  Batch 287/298, Loss: 0.009757
  Batch 288/298, Loss: 0.009730
  Batch 289/298, Loss: 0.009373
  Batch 290/298, Loss: 0.009546
  Batch 291/298, Loss: 0.009137
  Batch 292/298, Loss: 0.009203
  Batch 293/298, Loss: 0.008234
  Batch 294/298, Loss: 0.007591
  Batch 295/298, Loss: 0.006888
  Batch 296/298, Loss: 0.005698
  Batch 297/298, Loss: 0.005616
  Batch 298/298, Loss: 0.005554
executing train_step()
  Batch 299/298, Loss: 0.005530
[1m 1/47[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m20s[0m 453ms/step[1m 3/47[0m [32m━[0m[37m━━━━━━━━━━━━━━━━━━━[0m [1m1s[0m 32ms/step  [1m 5/47[0m [32m━━[0m[37m━━━━━━━━━━━━━━━━━━[0m [1m1s[0m 32ms/step[1m 7/47[0m [32m━━[0m[37m━━━━━━━━━━━━━━━━━━[0m [1m1s[0m 32ms/step[1m 9/47[0m [32m━━━[0m[37m━━━━━━━━━━━━━━━━━[0m [1m1s[0m 32ms/step[1m11/47[0m [32m━━━━[0m[37m━━━━━━━━━━━━━━━━[0m [1m1s[0m 32ms/step[1m13/47[0m [32m━━━━━[0m[37m━━━━━━━━━━━━━━━[0m [1m1s[0m 32ms/step[1m15/47[0m [32m━━━━━━[0m[37m━━━━━━━━━━━━━━[0m [1m1s[0m 32ms/step[1m17/47[0m [32m━━━━━━━[0m[37m━━━━━━━━━━━━━[0m [1m0s[0m 31ms/step[1m19/47[0m [32m━━━━━━━━[0m[37m━━━━━━━━━━━━[0m [1m0s[0m 31ms/step[1m21/47[0m [32m━━━━━━━━[0m[37m━━━━━━━━━━━━[0m [1m0s[0m 31ms/step[1m23/47[0m [32m━━━━━━━━━[0m[37m━━━━━━━━━━━[0m [1m0s[0m 31ms/step[1m25/47[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m0s[0m 31ms/step[1m27/47[0m [32m━━━━━━━━━━━[0m[37m━━━━━━━━━[0m [1m0s[0m 31ms/step[1m30/47[0m [32m━━━━━━━━━━━━[0m[37m━━━━━━━━[0m [1m0s[0m 30ms/step[1m32/47[0m [32m━━━━━━━━━━━━━[0m[37m━━━━━━━[0m [1m0s[0m 30ms/step[1m34/47[0m [32m━━━━━━━━━━━━━━[0m[37m━━━━━━[0m [1m0s[0m 30ms/step[1m36/47[0m [32m━━━━━━━━━━━━━━━[0m[37m━━━━━[0m [1m0s[0m 30ms/step[1m38/47[0m [32m━━━━━━━━━━━━━━━━[0m[37m━━━━[0m [1m0s[0m 30ms/step[1m40/47[0m [32m━━━━━━━━━━━━━━━━━[0m[37m━━━[0m [1m0s[0m 30ms/step[1m42/47[0m [32m━━━━━━━━━━━━━━━━━[0m[37m━━━[0m [1m0s[0m 30ms/step[1m44/47[0m [32m━━━━━━━━━━━━━━━━━━[0m[37m━━[0m [1m0s[0m 30ms/step[1m46/47[0m [32m━━━━━━━━━━━━━━━━━━━[0m[37m━[0m [1m0s[0m 30ms/step[1m47/47[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 39ms/step[1m47/47[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m2s[0m 39ms/step
executing save_mse_to_csv()
Filename: C:\Users\SaadSuleman\OneDrive - Techionik\Documents\Desktop\anomaly_latest\anomaly_detection.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
   122    867.3 MiB    867.3 MiB           1   @profile
   123                                         def save_mse_to_csv(mse_values, file_name, run_guid, anomaly_indices=None, video_type="training"):
   124    867.3 MiB      0.0 MiB           1       print("executing save_mse_to_csv()")
   125                                             # Set to an empty list if None is passed
   126    867.3 MiB      0.0 MiB           1       if anomaly_indices is None:
   127    867.3 MiB      0.0 MiB           1           anomaly_indices = []
   128                                             # Create directory if it doesn't exist
   129    867.3 MiB      0.0 MiB           1       os.makedirs(os.path.dirname(file_name), exist_ok=True)
   130                                         
   131    867.4 MiB      0.0 MiB           2       with open(file_name, 'w', newline='') as file:
   132    867.3 MiB      0.0 MiB           1           writer = csv.writer(file)
   133    867.3 MiB      0.0 MiB           1           writer.writerow(["GUID", "Frame Number", "Anomaly Score", "Anomaly Status"])
   134                                         
   135    867.4 MiB      0.0 MiB        1493           for i, mse in enumerate(mse_values):
   136    867.4 MiB      0.0 MiB        1492               if video_type == "training":
   137    867.4 MiB      0.0 MiB        1492                   status = "Normal"  # All frames in training video are normal
   138                                                     else:  # For testing video
   139                                                         status = "Anomaly" if i in anomaly_indices else "Normal"
   140    867.4 MiB      0.0 MiB        1492               writer.writerow([run_guid, i, mse, status])


Filename: C:\Users\SaadSuleman\OneDrive - Techionik\Documents\Desktop\anomaly_latest\anomaly_detection.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
   153    353.8 MiB    353.8 MiB           1   @profile
   154                                         def train_model(run_guid, input_epoch, train_video_path, anomaly_dir, app_version, folder_path, file_path):
   155    353.8 MiB      0.0 MiB           1       print("executing train_model()")
   156    353.8 MiB      0.0 MiB           1       start_time = datetime.now()
   157                                         
   158                                             # Training logic
   159    353.8 MiB      0.0 MiB           1       h, w = 128, 128
   160    353.8 MiB      0.0 MiB           1       input_video_path = train_video_path
   161    353.8 MiB      0.0 MiB           1       print("Input video path:", input_video_path)
   162    454.9 MiB    101.0 MiB           2       input_video, training_video_duration, training_load_and_preprocess_dur = load_and_preprocess_video(input_video_path,
   163    353.8 MiB      0.0 MiB           1                                                                                                          h, w)
   164                                         
   165    454.9 MiB      0.0 MiB           1       if input_video is None:
   166                                                 # Handle the case where loading and preprocessing failed
   167                                                 print("Error loading or preprocessing video. Aborting training.")
   168                                                 return 0, 0, 0, 0, 0
   169                                         
   170    454.9 MiB      0.0 MiB           1       print("Training video frames: ", len(input_video))
   171                                         
   172    454.9 MiB      0.0 MiB           1       epochs = input_epoch
   173                                         
   174                                             # Calculate total number of batches
   175    454.9 MiB      0.0 MiB           1       batch_size = 5
   176    454.9 MiB      0.0 MiB           1       total_batches = len(input_video) // batch_size * epochs
   177                                         
   178                                             # Counter for batches
   179    454.9 MiB      0.0 MiB           1       batch_counter = 0
   180                                         
   181    464.0 MiB      9.2 MiB           1       autoencoder, optimizer = build_autoencoder()
   182                                         
   183                                             # Initialize optimizer's state
   184    464.0 MiB      0.0 MiB           1       dummy_input = tf.ones((1, h, w, 1))  # Create a dummy input tensor
   185    475.7 MiB     11.7 MiB           1       autoencoder(dummy_input)
   186    475.7 MiB      0.0 MiB           1       optimizer.iterations  # This builds the optimizer's state
   187                                         
   188                                             # Train your model here using input_video and epochs
   189                                             # Convert input_epoch to integer
   190    475.7 MiB      0.0 MiB           1       epochs = int(input_epoch)
   191    563.9 MiB      0.0 MiB           2       for epoch in range(epochs):
   192    475.7 MiB      0.0 MiB           1           print("Epoch: ", epoch + 1)
   193    563.9 MiB      0.0 MiB         300           for i in range(0, len(input_video), batch_size):
   194    546.3 MiB      0.0 MiB         299               batch_input_video = input_video[i:i + batch_size]
   195    546.3 MiB      0.0 MiB         299               batch_target_video = input_video[i:i + batch_size]
   196    563.9 MiB     88.2 MiB         299               loss = train_step(batch_input_video, batch_target_video, autoencoder, optimizer)
   197    563.9 MiB      0.0 MiB         299               batch_counter += 1
   198                                                     #             progress = (batch_counter / total_batches) * 100
   199                                                     #             progress['value'] = progress
   200                                                     #             # Update the progress label
   201                                                     #             progress_label.config(text="{}%".format(int(progress)))
   202                                                     #             update_idletasks()
   203    563.9 MiB      0.0 MiB         299               print(f"  Batch {i // batch_size + 1}/{len(input_video) // batch_size}, Loss: {loss:.6f}")
   204                                         
   205    867.3 MiB    303.3 MiB           1       reconstructed_train_video = autoencoder.predict(input_video)
   206    867.3 MiB      0.1 MiB        1496       train_mse = [mean_squared_error(input_video[i].reshape(h, w), reconstructed_train_video[i].reshape(h, w)) for i in
   207    867.3 MiB      0.0 MiB           1                    range(len(input_video))]
   208    867.3 MiB      0.0 MiB           1       threshold = np.mean(train_mse)
   209                                         
   210    867.4 MiB      0.0 MiB           2       save_mse_to_csv(train_mse, os.path.join(anomaly_dir, "RTAD_v{}_training_anomaly_scores.csv".format(app_version)),
   211    867.3 MiB      0.0 MiB           1                       run_guid, video_type="training")
   212                                         
   213    867.4 MiB      0.0 MiB           1       end_time = datetime.now()
   214    867.4 MiB      0.0 MiB           1       training_duration = (end_time - start_time).seconds
   215                                         
   216    867.4 MiB      0.0 MiB           1       model_path = os.path.join(anomaly_dir, "RTAD_v{}_saved_model.h5".format(app_version))
   217    869.0 MiB      1.6 MiB           1       autoencoder.save(model_path)
   218                                         
   219    869.0 MiB      0.0 MiB           1       train_video_frames = len(input_video)
   220    869.0 MiB      0.0 MiB           1       gc.collect()
   221    869.0 MiB      0.0 MiB           1       return train_video_frames, training_duration, training_video_duration, training_load_and_preprocess_dur, input_epoch


Detecting anomalies...
executing build_autoencoder()
Encoding...
Decoding...
Building the autoencoder model...
Filename: C:\Users\SaadSuleman\OneDrive - Techionik\Documents\Desktop\anomaly_latest\anomaly_detection.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    82    682.5 MiB    682.5 MiB           1   @profile
    83                                         def build_autoencoder():
    84    682.5 MiB      0.0 MiB           1           print("executing build_autoencoder()")
    85                                                 # glogally 
    86    682.5 MiB      0.0 MiB           1           h, w = 128, 128
    87    682.5 MiB      0.0 MiB           1           input_img = Input(shape=(h, w, 1)) # channel 1 (gray scale) or 3 (coloured images)
    88                                         
    89                                                 # Encoding
    90    682.5 MiB      0.0 MiB           1           print("Encoding...")
    91    682.5 MiB      0.0 MiB           1           x = Conv2D(16, (3, 3), activation="relu", padding="same")(input_img)
    92    682.5 MiB      0.0 MiB           1           x = MaxPooling2D((2, 2), padding="same")(x)
    93    682.5 MiB      0.0 MiB           1           x = Conv2D(8, (3, 3), activation="relu", padding="same")(x)
    94    682.5 MiB      0.0 MiB           1           x = Conv2D(8, (3, 3), activation="relu", padding="same")(x)
    95    682.5 MiB      0.0 MiB           1           encoded = MaxPooling2D((2, 2), padding="same")(x)
    96                                         
    97                                                 # Decoding
    98    682.5 MiB      0.0 MiB           1           print("Decoding...")
    99    682.5 MiB      0.0 MiB           1           x = Conv2D(8, (3, 3), activation="relu", padding="same")(encoded)
   100    682.5 MiB      0.0 MiB           1           x = UpSampling2D((2, 2))(x)
   101    682.5 MiB      0.0 MiB           1           x = Conv2D(16, (3, 3), activation="relu", padding="same")(x)
   102    682.5 MiB      0.0 MiB           1           x = Conv2D(16, (3, 3), activation="relu", padding="same")(x)
   103    682.5 MiB      0.0 MiB           1           x = UpSampling2D((2, 2))(x)
   104    682.5 MiB      0.0 MiB           1           decoded = Conv2D(1, (3, 3), activation="sigmoid", padding="same")(x)
   105                                         
   106                                                 # Build the autoencoder model
   107    682.5 MiB      0.0 MiB           1           print("Building the autoencoder model...")
   108    682.5 MiB      0.0 MiB           1           autoencoder = Model(input_img, decoded)
   109    682.5 MiB      0.0 MiB           1           autoencoder.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.MeanSquaredError())
   110                                         
   111    682.5 MiB      0.0 MiB           1           optimizer = tf.keras.optimizers.Adam()
   112                                         
   113    682.5 MiB      0.0 MiB           1           return autoencoder, optimizer


executing load_and_preprocess_video()
Video path: uploads\test_upload\Fake.mp4
Filename: C:\Users\SaadSuleman\OneDrive - Techionik\Documents\Desktop\anomaly_latest\anomaly_detection.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    20    682.5 MiB    682.5 MiB           1   @profile
    21                                         def load_and_preprocess_video(video_path, h, w, return_original=False):
    22    682.5 MiB      0.0 MiB           1       print("executing load_and_preprocess_video()")
    23    682.5 MiB      0.0 MiB           1       start_time = datetime.now()
    24                                         
    25    682.5 MiB      0.0 MiB           1       print("Video path:", video_path)  # Add this line for debugging
    26                                         
    27    683.5 MiB      1.0 MiB           1       cap = cv2.VideoCapture(video_path)
    28                                         
    29                                             # Check if video opened successfully
    30    683.5 MiB      0.0 MiB           1       if not cap.isOpened():
    31                                                 print("Error opening video file:", video_path)  # Add this line for debugging
    32                                                 return None, 0, 0  # Return None along with other values if video cannot be opened
    33                                         
    34    683.5 MiB      0.0 MiB           1       frames = []
    35    683.5 MiB      0.0 MiB           1       original_frames = []
    36                                         
    37    683.5 MiB      0.0 MiB           1       try:
    38                                                 # Get total number of frames in the video
    39    683.5 MiB      0.0 MiB           1           total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    40                                         
    41                                                 # Get frames per second (FPS) of the video
    42    683.5 MiB      0.0 MiB           1           fps = cap.get(cv2.CAP_PROP_FPS)
    43                                         
    44                                                 # Calculate video duration in seconds
    45    683.5 MiB      0.0 MiB           1           video_duration = total_frames / fps
    46                                         
    47   2491.5 MiB      0.0 MiB         660           while True:
    48   2491.5 MiB   1765.8 MiB         660               ret, frame = cap.read()
    49   2491.5 MiB      0.0 MiB         660               if not ret:
    50   2491.5 MiB      0.0 MiB           1                   break
    51   2491.5 MiB      0.0 MiB         659               if return_original:
    52   2491.5 MiB      0.0 MiB         659                   original_frames.append(frame)
    53                                         
    54                                                     # (128,128,1 or 3)
    55   2491.5 MiB     26.4 MiB         659               frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    56   2491.5 MiB      0.0 MiB         659               frame = cv2.resize(frame, (h, w))
    57                                                     # Normalizing (why?)
    58   2491.5 MiB     15.8 MiB         659               frame = frame.astype("float32") / 255.0
    59   2491.5 MiB      0.0 MiB         659               frames.append(frame)
    60                                         
    61   2464.3 MiB    -27.2 MiB           1           cap.release()
    62   2505.5 MiB     41.2 MiB           1           video = np.array(frames)
    63   2505.5 MiB      0.0 MiB           1           video = np.expand_dims(video, axis=-1)
    64                                         
    65   2505.5 MiB      0.0 MiB           1           end_time = datetime.now()
    66   2505.5 MiB      0.0 MiB           1           load_and_preprocess_video_duration = (end_time - start_time).seconds
    67                                         
    68   2505.5 MiB      0.0 MiB           1           if return_original:
    69   2505.5 MiB      0.0 MiB           1               return video, video_duration, original_frames, load_and_preprocess_video_duration
    70                                                 else:
    71                                                     return video, video_duration, load_and_preprocess_video_duration
    72                                         
    73                                             except Exception as e:
    74                                                 print("Error processing video:", e)
    75                                                 return None, 0, 0
    76                                             if return_original:
    77                                                 return video, video_duration, original_frames, load_and_preprocess_video_duration
    78                                             else:
    79                                                 return video, video_duration, load_and_preprocess_video_duration


Testing video frames:  659
[1m 1/21[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m18s[0m 901ms/step[1m 3/21[0m [32m━━[0m[37m━━━━━━━━━━━━━━━━━━[0m [1m0s[0m 45ms/step  [1m 5/21[0m [32m━━━━[0m[37m━━━━━━━━━━━━━━━━[0m [1m0s[0m 46ms/step[1m 7/21[0m [32m━━━━━━[0m[37m━━━━━━━━━━━━━━[0m [1m0s[0m 46ms/step[1m 9/21[0m [32m━━━━━━━━[0m[37m━━━━━━━━━━━━[0m [1m0s[0m 45ms/step[1m11/21[0m [32m━━━━━━━━━━[0m[37m━━━━━━━━━━[0m [1m0s[0m 46ms/step[1m13/21[0m [32m━━━━━━━━━━━━[0m[37m━━━━━━━━[0m [1m0s[0m 47ms/step[1m15/21[0m [32m━━━━━━━━━━━━━━[0m[37m━━━━━━[0m [1m0s[0m 46ms/step[1m17/21[0m [32m━━━━━━━━━━━━━━━━[0m[37m━━━━[0m [1m0s[0m 44ms/step[1m19/21[0m [32m━━━━━━━━━━━━━━━━━━[0m[37m━━[0m [1m0s[0m 43ms/step